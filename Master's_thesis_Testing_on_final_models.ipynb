{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master's thesis - Testing on final models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Detectron2 and its dependencies"
      ],
      "metadata": {
        "id": "yQVU6EUaY63E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n"
      ],
      "metadata": {
        "id": "dEskRgzvY_f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ngLIO2jSZBkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\") \n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "#Import some common imports\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
        "import detectron2\n",
        "import logging\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "#imports to the validation hook\n",
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper\n",
        "import detectron2.utils.comm as comm\n",
        "import time\n",
        "import datetime\n",
        "from detectron2.engine import launch"
      ],
      "metadata": {
        "id": "DsGBb0BzZC2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "9MpPCbH5ZG8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to drive"
      ],
      "metadata": {
        "id": "lUdHX8bebzgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') #This step should be avoided if data is not placed on drive"
      ],
      "metadata": {
        "id": "AWAKivVpb17I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the following code has taken inspiration from different resources: The custom mapper has taken inspiration from the \"VinBigData detectron2 train\" kaggle. URL: https://www.kaggle.com/code/corochann/vinbigdata-detectron2-train. \n",
        "The function to convert data to coco format has taken inspiration from the \"Detectron 2 compare models + augmentation\" kaggle. URL:https://www.kaggle.com/code/dhiiyaur/detectron-2-compare-models-augmentation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gL5BKAsq0aAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make function to convert data to COCO format"
      ],
      "metadata": {
        "id": "qvkZpSiyb2D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = filename\n",
        "        record[\"height\"] = 480\n",
        "        record[\"width\"] = 640\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly \n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "XnRCpm-Fb42U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make custom mapper for data augmentation"
      ],
      "metadata": {
        "id": "UIEmUKVTb4_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)  \n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    transform_list = [\n",
        "        T.RandomBrightness(0.4, 1.3),\n",
        "        T.RandomCrop('relative_range', (0.6, 0.6)),\n",
        "        T.RandomFlip(prob=0.4, horizontal=True, vertical=False), \n",
        "    ]\n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "        if obj.get(\"iscrowd\", 0) == 0\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "    return dataset_dict\n"
      ],
      "metadata": {
        "id": "d5ZeO-OCcAlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make customer trainer called Trainer"
      ],
      "metadata": {
        "id": "RPlTzQtWcDj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper) #tells it to do augmentation\n"
      ],
      "metadata": {
        "id": "kXkQb_6zcI_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data "
      ],
      "metadata": {
        "id": "bzwAQ0u9cJHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List the five classes \n",
        "classes = ['sink', 'door', 'bed', 'screen', 'socket']\n",
        "\n",
        "#Give path to data - if path is not on drive change the path before running\n",
        "data_path = '/content/drive/MyDrive/robotdata/Final_Dataset/'\n",
        "\n",
        "\n",
        "for d in [\"train\", \"test\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"robot_\" + d, \n",
        "        lambda d=d: get_data_dicts(data_path+d, classes) #uses get_data_dicts function to make data into COCO format\n",
        "    )\n",
        "    MetadataCatalog.get(\"robot_\" + d).set(thing_classes=classes)\n",
        "\n",
        "#Collect the data into metadatacatalog \n",
        "microcontroller_metadata = MetadataCatalog.get(\"robot_train\")\n",
        "\n",
        "#Convert trainingset to COCO format and save as train_dicts\n",
        "train_dicts = get_data_dicts(data_path+'train', classes)\n",
        "\n",
        "#Convert testset to COCO format and save as test_dicts\n",
        "test_dicts = get_data_dicts(data_path+'test', classes)"
      ],
      "metadata": {
        "id": "Fk-_SGGNcK4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize loaded data"
      ],
      "metadata": {
        "id": "cdn1webjcLBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize for checking the data is loaded properly \n",
        "for d in random.sample(train_dicts, 5):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GZUe1Dd8czol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final models"
      ],
      "metadata": {
        "id": "5ps5usb_c1f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R50"
      ],
      "metadata": {
        "id": "DZnwl3jLc8ZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "1HfOdbEwc-hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ()  \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 #set to four for collab to run due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 3800 #iterations\n",
        "cfg.SOLVER.STEPS = (500, 1000, 1500, 2000, 2500, 3000, 3500)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr= 0.05\n",
        "g=0.5\n",
        "wd=0.00025\n",
        "cfg.SOLVER.BASE_LR = lr\n",
        "cfg.SOLVER.GAMMA = g\n",
        "cfg.SOLVER.WEIGHT_DECAY = wg\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #Create directory for output\n",
        "trainer= Trainer(cfg) #Use custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() #train model"
      ],
      "metadata": {
        "id": "ixQWRIGsdAom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "bcbCg_r2dSE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "JZolxAtDdUkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test final model on testset"
      ],
      "metadata": {
        "id": "A9MGSjs9fB9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test model"
      ],
      "metadata": {
        "id": "z8Ezb6hRdfQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6 #Set threshold\n",
        "cfg.DATASETS.TEST = (\"robot_test\",) #give testset\n",
        "predictor = DefaultPredictor(cfg) #Predict on testset "
      ],
      "metadata": {
        "id": "Fb3Q4YaLdjQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Matrices"
      ],
      "metadata": {
        "id": "q2G_P5E9djao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluator = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"robot_test\") #evaluate on testset\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator)) #Print evaluation"
      ],
      "metadata": {
        "id": "JrTgYFp3dm8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "Ak7aiI4HdnJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize all 35 images from testset\n",
        "for d in random.sample(test_dicts, 35):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "3u3Dqwk0dqZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "T1irIegXfeXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory=str(lr)+\"_\"+str(g)+\"_\"+str(wd)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "zbk6kgCdffZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101"
      ],
      "metadata": {
        "id": "ggUOClLndUy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "vs5ai8hZfI2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = () \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 #Set to four so collab can run it due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 3000 # iterations\n",
        "cfg.SOLVER.STEPS = (1000, 2000, 3000)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr= 0.07\n",
        "g= 0.1\n",
        "wd = 0.00025\n",
        "cfg.SOLVER.BASE_LR =lr\n",
        "cfg.SOLVER.GAMMA =g\n",
        "cfg.SOLVER.WEIGHT_DECAY =wd\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #Make directory for output\n",
        "trainer= Trainer(cfg)  #Use customtrainer with dataaugmentation\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() # train model"
      ],
      "metadata": {
        "id": "4GRh2qnmfKPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "PznNlbNwfKYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "SUVU9Nq5fM3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test final model on testset"
      ],
      "metadata": {
        "id": "FLSa8d0NfNBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test model"
      ],
      "metadata": {
        "id": "pbYyodQwfSVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6 #Set threshold\n",
        "cfg.DATASETS.TEST = (\"robot_test\",) #give testset\n",
        "predictor = DefaultPredictor(cfg) #Predict on testset "
      ],
      "metadata": {
        "id": "rT6J3y3IfQbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Matrices"
      ],
      "metadata": {
        "id": "bKQKYicMfQkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluator = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"robot_test\") #evaluate on testset\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator)) #Print evaluation"
      ],
      "metadata": {
        "id": "H10szE-9fWzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "EuvcJ3-kdA5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize all 35 images from testset\n",
        "for d in random.sample(test_dicts, 35):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "5T7gZyoXc7oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "3F0oZM4Yfb_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory=str(lr)+\"_\"+str(g)+\"_\"+str(wd)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "DI2wjIQ-hY_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R50 baseline model"
      ],
      "metadata": {
        "id": "DPptUlr_hnwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "0vSgpeTshq-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) # Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ('robot_valid',)  \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 #Set to four else it cannot run on collab due to resource limitations\n",
        "cfg.SOLVER.MAX_ITER = 3000\n",
        "cfg.SOLVER.STEPS = ()\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 # Number of classes \n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #Make directory for output of model\n",
        "trainer = Trainer(cfg) # Use custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() #Train model"
      ],
      "metadata": {
        "id": "SQYHtpoXhtPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "CcmhZkxLhtZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "cWdtrx1thvYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing baseline model on testset"
      ],
      "metadata": {
        "id": "sZug2IyVhvhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test model"
      ],
      "metadata": {
        "id": "flNns4ikh1bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6 #Set threshold\n",
        "cfg.DATASETS.TEST = (\"robot_test\",) #give testset\n",
        "predictor = DefaultPredictor(cfg) #Predict on testset "
      ],
      "metadata": {
        "id": "xl65CHYjhzI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Matrices"
      ],
      "metadata": {
        "id": "q7m52ARfhzXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluator = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"robot_test\") #evaluate on testset\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator)) #Print evaluation"
      ],
      "metadata": {
        "id": "c6NA1zzjh5lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "kz5myZSVihdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize all 35 images from testset\n",
        "for d in random.sample(test_dicts, 35):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "VZ0eRfqeimZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "b_q6Mfy0h5y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 50\n",
        "iter = 3000\n",
        "directory=str(model)+\"_\"+str(iter)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "WVLQQ85diFA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101 Baseline model"
      ],
      "metadata": {
        "id": "UprpV9aTiFMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "i2qhkOBtiHkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ()  \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 # Set to 4 to run on collab due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 3000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #Make output directory \n",
        "trainer = Trainer(cfg) #Use custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()# train model"
      ],
      "metadata": {
        "id": "tYTdzXohiIuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "Hd8_2qRiiI3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "k50M9_HeiKFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing baseline model on testset"
      ],
      "metadata": {
        "id": "x4XVJNj0iKOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test model"
      ],
      "metadata": {
        "id": "vBd_8RQGiSEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6 #Set threshold\n",
        "cfg.DATASETS.TEST = (\"robot_test\",) #give testset\n",
        "predictor = DefaultPredictor(cfg) #Predict on testset "
      ],
      "metadata": {
        "id": "SK8ueWgGiTPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Matrices"
      ],
      "metadata": {
        "id": "HNm29hn-iTYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluator = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"robot_test\") #evaluate on testset\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator)) #Print evaluation"
      ],
      "metadata": {
        "id": "0J4vimhfiVCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "Z6JQBUrciWJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize all 35 images from testset\n",
        "for d in random.sample(test_dicts, 35):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "lXex3HWHinnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "M44k4goalP2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 101\n",
        "iter = 3000\n",
        "directory=str(model)+\"_\"+str(iter)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "K8ufIaHjlRKM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}