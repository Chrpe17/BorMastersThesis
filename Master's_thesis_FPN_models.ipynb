{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master's thesis - FPN models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bT2TY2OJAE8i",
        "8scrnhbXAZLy",
        "ZZpw2f_MAb4o",
        "8bXlPCeLCbXu",
        "HsCQHmqBChCI",
        "kROg75kQClrS",
        "IsKB82SkFsbN",
        "QalIXOYcFx_O",
        "H0G4Wd9PF2Ly",
        "jEYMhN9uH7iP",
        "u_Vr6KCjIFD6",
        "_luJvAt6IHWJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Detectron2 and its dependencies"
      ],
      "metadata": {
        "id": "UuwDBu0a-veI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n"
      ],
      "metadata": {
        "id": "K_kAao8i-zAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "GimNplwJ-_zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\") \n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "#Import some common imports\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()"
      ],
      "metadata": {
        "id": "379jrppy_Am8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "Mc7XZfdf_DFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to drive"
      ],
      "metadata": {
        "id": "CmA9OpsA_FSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') #This step should be avoided if data is not placed on drive"
      ],
      "metadata": {
        "id": "pFaiNke0_GxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the following code has taken inspiration from different resources: \n",
        "The function to convert data to coco format has taken inspiration from the \"Detectron 2 compare models + augmentation\" kaggle. URL:https://www.kaggle.com/code/dhiiyaur/detectron-2-compare-models-augmentation"
      ],
      "metadata": {
        "id": "7mgZSipE6aKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make function to convert data to COCO format"
      ],
      "metadata": {
        "id": "Pc7cQKUi_G75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = filename\n",
        "        record[\"height\"] = 480\n",
        "        record[\"width\"] = 640\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly \n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "ZskvBDv2_KkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "MA2xgNB7_Kto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List the five classes \n",
        "classes = ['sink', 'door', 'bed', 'screen', 'socket']\n",
        "\n",
        "#Give path to data - if path is not on drive change the path before running\n",
        "data_path = '/content/drive/MyDrive/robotdata/Blue_ocean_dataset1/'\n",
        "\n",
        "for d in [\"train\", \"valid\", \"test\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"robot_\" + d, \n",
        "        lambda d=d: get_data_dicts(data_path+d, classes) #uses get_data_dicts function to make data into COCO format\n",
        "    )\n",
        "    MetadataCatalog.get(\"robot_\" + d).set(thing_classes=classes)\n",
        "\n",
        "#Collect the data into metadatacatalog \n",
        "microcontroller_metadata = MetadataCatalog.get(\"robot_train\")\n",
        "\n",
        "#Convert trainingset to COCO format and save as train_dicts\n",
        "train_dicts = get_data_dicts(data_path+'train', classes)\n",
        "\n",
        "#Convert validationset to COCO format and save as valid_dicts\n",
        "valid_dicts = get_data_dicts(data_path+'valid', classes)\n"
      ],
      "metadata": {
        "id": "11v6HZ5E_W5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize loaded data"
      ],
      "metadata": {
        "id": "uv-20Jd2_XES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize for checking the data is loaded properly \n",
        "for d in random.sample(train_dicts, 5):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "astsRaUO_nX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing 4 chosen FPN models"
      ],
      "metadata": {
        "id": "R06Tk6kF_oe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101 - FPN"
      ],
      "metadata": {
        "id": "Hc98fsuJ_uh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "mDw2BMqAAR9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_r101 = get_cfg()\n",
        "cfg_fpn_r101.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) #Load model\n",
        "cfg_fpn_r101.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_fpn_r101.DATASETS.TEST = ()  \n",
        "cfg_fpn_r101.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_fpn_r101.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\") #Load weights\n",
        "cfg_fpn_r101.SOLVER.IMS_PER_BATCH = 4 # Set to 4 to run on collab due to limited resources\n",
        "cfg_fpn_r101.SOLVER.MAX_ITER = 1000\n",
        "cfg_fpn_r101.SOLVER.STEPS = []\n",
        "cfg_fpn_r101.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "os.makedirs(cfg_fpn_r101.OUTPUT_DIR, exist_ok=True) #Make output directory \n",
        "trainer_fpn_r101 = DefaultTrainer(cfg_fpn_r101) #Use default trainer\n",
        "trainer_fpn_r101.resume_or_load(resume=False)\n",
        "trainer_fpn_r101.train()# train model"
      ],
      "metadata": {
        "id": "cJtb78tSAEvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "bT2TY2OJAE8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "WZogCokyAP4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "kAfCtAT0AQCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_r101.MODEL.WEIGHTS = os.path.join(cfg_fpn_r101.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_fpn_r101.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 #Set threshold\n",
        "cfg_fpn_r101.DATASETS.TEST = (\"robot_valid\",) #Give validation set to predict on\n",
        "predictor_fpn_r101 = DefaultPredictor(cfg_fpn_r101) #Make predictions"
      ],
      "metadata": {
        "id": "Jb_QsSOfAY8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "8scrnhbXAZLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_fpn_r101 = COCOEvaluator(\"robot_valid\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader_fpn_r101 = build_detection_test_loader(cfg_fpn_r101, \"robot_valid\") #Give validation set\n",
        "print(inference_on_dataset(predictor_fpn_r101.model, val_loader_fpn_r101, evaluator_fpn_r101)) #Print predictions"
      ],
      "metadata": {
        "id": "PGl5DNEGAbje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "ZZpw2f_MAb4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gives five random predictions from prediction\n",
        "for d in random.sample(valid_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_fpn_r101(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "  plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "-ka9y_6UAfxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "jtN9OMQpAgbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_fpn_r101, 'model_final.pth')"
      ],
      "metadata": {
        "id": "uYLi-vRhBwgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X101-FPN"
      ],
      "metadata": {
        "id": "y0toMDRHBy-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train baseline model"
      ],
      "metadata": {
        "id": "X3_vEj2iB3n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_x101 = get_cfg()\n",
        "cfg_fpn_x101.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")) #Load model\n",
        "cfg_fpn_x101.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_fpn_x101.DATASETS.TEST = ()  \n",
        "cfg_fpn_x101.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_fpn_x101.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\") #Load weights\n",
        "cfg_fpn_x101.SOLVER.IMS_PER_BATCH = 4 # Set to four to make collab able to run due to limited resources\n",
        "cfg_fpn_x101.SOLVER.MAX_ITER = 1000\n",
        "cfg_fpn_x101.SOLVER.STEPS = []\n",
        "cfg_fpn_x101.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "os.makedirs(cfg_fpn_x101.OUTPUT_DIR, exist_ok=True) #Make directory for output\n",
        "trainer_fpn_x101 = DefaultTrainer(cfg_fpn_x101) #Use default trainer\n",
        "trainer_fpn_x101.resume_or_load(resume=False)\n",
        "trainer_fpn_x101.train() #Train model"
      ],
      "metadata": {
        "id": "zcmjYxciCbL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "8bXlPCeLCbXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "vtx4ZhhGCdS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "ZSBd0lhMCddJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_x101.MODEL.WEIGHTS = os.path.join(cfg_fpn_x101.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_fpn_x101.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # Set threshold\n",
        "cfg_fpn_x101.DATASETS.TEST = (\"robot_valid\",) #give validation set\n",
        "predictor_fpn_x101 = DefaultPredictor(cfg_fpn_x101) # Predict on validation set"
      ],
      "metadata": {
        "id": "E0I5BtI0CgzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "HsCQHmqBChCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_fpn_x101 = COCOEvaluator(\"robot_valid\", output_dir=\"./output\") #Use coco evaluator\n",
        "val_loader_fpn_x101 = build_detection_test_loader(cfg_fpn_x101, \"robot_valid\") #Predict on validationset\n",
        "print(inference_on_dataset(predictor_fpn_x101.model, val_loader_fpn_x101, evaluator_fpn_x101)) #Print evaluation matrix"
      ],
      "metadata": {
        "id": "pTVBdYwVCliV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "kROg75kQClrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gives five random predictions from prediction\n",
        "for d in random.sample(valid_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_fpn_r101(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "  plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "NB3c-OSVCpjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "F6TKSYw_Cpr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_fpn_x101, 'model_final.pth')"
      ],
      "metadata": {
        "id": "XjTUaLatByMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101-Retina"
      ],
      "metadata": {
        "id": "GdJywhfCFoT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "X-ElxlP1FqBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_re = get_cfg()\n",
        "cfg_fpn_re.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")) #Load model\n",
        "cfg_fpn_re.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_fpn_re.DATASETS.TEST = ()  \n",
        "cfg_fpn_re.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_fpn_re.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\") #Load weights\n",
        "cfg_fpn_re.SOLVER.IMS_PER_BATCH = 4 #set to four to be able to run on collab due to limited resources\n",
        "cfg_fpn_re.SOLVER.MAX_ITER = 1000\n",
        "cfg_fpn_re.SOLVER.STEPS = []\n",
        "cfg_fpn_re.MODEL.RETINANET.NUM_CLASSES = 5 # Number of classes\n",
        "\n",
        "os.makedirs(cfg_fpn_re.OUTPUT_DIR, exist_ok=True) #create directory for output\n",
        "trainer_fpn_re = DefaultTrainer(cfg_fpn_re) # Use default trainer\n",
        "trainer_fpn_re.resume_or_load(resume=False)\n",
        "trainer_fpn_re.train() # Train model"
      ],
      "metadata": {
        "id": "m2NEOE3fFr8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "IsKB82SkFsbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "q4qPrixDFuiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "UCC8gH0EFusg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_re.MODEL.WEIGHTS = os.path.join(cfg_fpn_re.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_fpn_re.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7 #Set threshold\n",
        "cfg_fpn_re.DATASETS.TEST = (\"robot_valid\",) #Give validation set\n",
        "predictor_fpn_re = DefaultPredictor(cfg_fpn_re) # Predict on validation set"
      ],
      "metadata": {
        "id": "gHqcZj_wFwQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "QalIXOYcFx_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_fpn_re = COCOEvaluator(\"robot_valid\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader_fpn_re = build_detection_test_loader(cfg_fpn_re, \"robot_valid\") # Evaluate on validation set\n",
        "print(inference_on_dataset(predictor_fpn_re.model, val_loader_fpn_re, evaluator_fpn_re)) #print evaluation"
      ],
      "metadata": {
        "id": "j1bCYGIKF1K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "H0G4Wd9PF2Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gives five random predictions from prediction\n",
        "for d in random.sample(valid_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_fpn_r101(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "  plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "HI8sn7rWF4o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "cTmoS1yXF5Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_fpn_re, 'model_final.pth')"
      ],
      "metadata": {
        "id": "eSWHjC8PGs-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R50-FPN"
      ],
      "metadata": {
        "id": "gLkOrO2sHNV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "6wnf24pdH4Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_fast_r50 = get_cfg()\n",
        "cfg_fpn_fast_r50.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) # Load model\n",
        "cfg_fpn_fast_r50.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_fpn_fast_r50.DATASETS.TEST = ()  \n",
        "cfg_fpn_fast_r50.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_fpn_fast_r50.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") # Load weights\n",
        "cfg_fpn_fast_r50.SOLVER.IMS_PER_BATCH = 4 #set to four to make collab able to run due to limited resources\n",
        "cfg_fpn_fast_r50.SOLVER.MAX_ITER = 1000\n",
        "cfg_fpn_fast_r50.SOLVER.STEPS = []\n",
        "cfg_fpn_fast_r50.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "os.makedirs(cfg_fpn_fast_r50.OUTPUT_DIR, exist_ok=True) #Make directory for output from model\n",
        "trainer_fpn_fast_r50 = DefaultTrainer(cfg_fpn_fast_r50) # Use default trainer\n",
        "trainer_fpn_fast_r50.resume_or_load(resume=False)\n",
        "trainer_fpn_fast_r50.train() #Train model"
      ],
      "metadata": {
        "id": "Kcz9ynyQHfDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "jEYMhN9uH7iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "AxQUwXh2H_5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "MNVTGGN7IAHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn_fast_r50.MODEL.WEIGHTS = os.path.join(cfg_fpn_fast_r50.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_fpn_fast_r50.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 #Set threshold\n",
        "cfg_fpn_fast_r50.DATASETS.TEST = (\"robot_valid\",) #Give validationset\n",
        "predictor_fpn_fast_r50 = DefaultPredictor(cfg_fpn_fast_r50) #Predict on validationset"
      ],
      "metadata": {
        "id": "_m8_tN6yIDL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "u_Vr6KCjIFD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluator_fpn_fast_r50 = COCOEvaluator(\"robot_valid\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader_fpn_fast_r50 = build_detection_test_loader(cfg_fpn_fast_r50, \"robot_valid\") #Evaluate on validationset\n",
        "print(inference_on_dataset(predictor_fpn_fast_r50.model, val_loader_fpn_fast_r50, evaluator_fpn_fast_r50)) #Print evaluation "
      ],
      "metadata": {
        "id": "vii-oHrGIHM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "_luJvAt6IHWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gives five random predictions from prediction\n",
        "for d in random.sample(valid_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_fpn_r101(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "  plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "ZWAmVgabIJ76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "uVV8Vah8IKK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_fpn_fast_r50, 'model_final.pth')"
      ],
      "metadata": {
        "id": "ALkTSicrILRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}