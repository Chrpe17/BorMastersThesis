{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master's Thesis - Hyperparameter search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Detectron2 and its dependencies"
      ],
      "metadata": {
        "id": "8CAm-qKeLiZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n"
      ],
      "metadata": {
        "id": "Do6Ba16WLl8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "nv6JwYVZLmHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\") \n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "#Import some common imports\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
        "import detectron2\n",
        "import logging\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "#imports to the validation hook\n",
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper\n",
        "import detectron2.utils.comm as comm\n",
        "import time\n",
        "import datetime\n",
        "from detectron2.engine import launch\n"
      ],
      "metadata": {
        "id": "FlbP-VPmLn7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "vy1FZLqgLoH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to drive"
      ],
      "metadata": {
        "id": "mfYG5eITL8MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') #This step should be avoided if data is not placed on drive"
      ],
      "metadata": {
        "id": "WmI4rz0uL_DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the following code has taken inspiration from different resources: The custom mapper and loss hook has taken inspiration from the \"VinBigData detectron2 train\" kaggle. URL: https://www.kaggle.com/code/corochann/vinbigdata-detectron2-train. \n",
        "The function to convert data to coco format has taken inspiration from the \"Detectron 2 compare models + augmentation\" kaggle. URL:https://www.kaggle.com/code/dhiiyaur/detectron-2-compare-models-augmentation\n"
      ],
      "metadata": {
        "id": "qMhcvtEn3CC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make function to convert data to COCO format"
      ],
      "metadata": {
        "id": "w3S6m0fCMCco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = filename\n",
        "        record[\"height\"] = 480\n",
        "        record[\"width\"] = 640\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly \n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "JCX9xHnQMGiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make custom mapper for data augmentation"
      ],
      "metadata": {
        "id": "jUT2yc4RML1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)  \n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    transform_list = [\n",
        "        T.RandomBrightness(0.4, 1.3),\n",
        "        T.RandomCrop('relative_range', (0.6, 0.6)),\n",
        "        T.RandomFlip(prob=0.4, horizontal=True, vertical=False), \n",
        "    ]\n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "        if obj.get(\"iscrowd\", 0) == 0\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "    return dataset_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "1cpxGyWrMRJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make validation loss hook "
      ],
      "metadata": {
        "id": "N8uMBdkNMhA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossHook(HookBase):\n",
        "    def __init__(self, eval_period, model, data_loader):\n",
        "        self._model = model\n",
        "        self._period = eval_period\n",
        "        self._data_loader = data_loader\n",
        "    \n",
        "    def _do_loss_eval(self):\n",
        "        total = len(self._data_loader)\n",
        "        num_warmup = min(5, total - 1)\n",
        "            \n",
        "        start_time = time.perf_counter()\n",
        "        total_compute_time = 0\n",
        "        losses = []\n",
        "        for idx, inputs in enumerate(self._data_loader):            \n",
        "            if idx == num_warmup:\n",
        "                start_time = time.perf_counter()\n",
        "                total_compute_time = 0\n",
        "            start_compute_time = time.perf_counter()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            total_compute_time += time.perf_counter() - start_compute_time\n",
        "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
        "            seconds_per_img = total_compute_time / iters_after_start\n",
        "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
        "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
        "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
        "                log_every_n_seconds(\n",
        "                    logging.INFO,\n",
        "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
        "                        idx + 1, total, seconds_per_img, str(eta)\n",
        "                    ),\n",
        "                    n=5,\n",
        "                )\n",
        "            loss_batch = self._get_loss(inputs)\n",
        "            losses.append(loss_batch)\n",
        "        mean_loss = np.mean(losses)\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
        "        comm.synchronize()\n",
        "\n",
        "        return losses\n",
        "            \n",
        "    def _get_loss(self, data):\n",
        "        metrics_dict = self._model(data)\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
        "        return total_losses_reduced\n",
        "        \n",
        "        \n",
        "    def after_step(self):\n",
        "        next_iter = self.trainer.iter + 1\n",
        "        is_final = next_iter == self.trainer.max_iter\n",
        "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
        "            self._do_loss_eval()\n",
        "        self.trainer.storage.put_scalars(timetest=12)\n"
      ],
      "metadata": {
        "id": "8MdVCYPoNIZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make custom trainer called Trainer"
      ],
      "metadata": {
        "id": "qTc-TSSOOIXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper) #tells it to do augmentation\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "                     \n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1,LossHook(\n",
        "            cfg.TEST.EVAL_PERIOD,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg,True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks"
      ],
      "metadata": {
        "id": "FsqrJ_3DONHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "ouQ3XY-FOZQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List the five classes \n",
        "classes = ['sink', 'door', 'bed', 'screen', 'socket']\n",
        "\n",
        "#Give path to data - if path is not on drive change the path before running\n",
        "data_path = '/content/drive/MyDrive/robotdata/Blue_ocean_dataset2/'\n",
        "\n",
        "for d in [\"train\", \"valid\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"robot_\" + d, \n",
        "        lambda d=d: get_data_dicts(data_path+d, classes) #uses get_data_dicts function to make data into COCO format\n",
        "    )\n",
        "    MetadataCatalog.get(\"robot_\" + d).set(thing_classes=classes)\n",
        "\n",
        "#Collect the data into metadatacatalog \n",
        "microcontroller_metadata = MetadataCatalog.get(\"robot_train\")\n",
        "\n",
        "#Convert trainingset to COCO format and save as train_dicts\n",
        "train_dicts = get_data_dicts(data_path+'train', classes)\n",
        "\n",
        "#Convert validationset to COCO format and save as valid_dicts\n",
        "valid_dicts = get_data_dicts(data_path+'valid', classes)"
      ],
      "metadata": {
        "id": "ZNKF-lMGOakC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize loaded data"
      ],
      "metadata": {
        "id": "78IcYPdCOav9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize for checking the data is loaded properly \n",
        "for d in random.sample(train_dicts, 5):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OUrMdQkGOgyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter search part 1: Lr and gamma values"
      ],
      "metadata": {
        "id": "XPlpM7rxSeD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R50"
      ],
      "metadata": {
        "id": "Hqw9AMFtSj-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "hOS567CKUXeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ('robot_valid',)  #Give validationset to validate on \n",
        "cfg.TEST.EVAL_PERIOD = 200 #For every 200 iter it will track on validation set\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") #Load model\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 #Set to four to run on collab due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 2000 \n",
        "cfg.SOLVER.STEPS = (200)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr= 0.00025 # 0.03, 0.1 - replace variable with the desired lr option\n",
        "g= 0.1 # 0.01, 0.5 - replace variable with the desired gamma option\n",
        "cfg.SOLVER.BASE_LR = lr\n",
        "cfg.SOLVER.GAMMA = g\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #create output directory for output\n",
        "trainer= Trainer(cfg) #Use custom trainer\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() #train model"
      ],
      "metadata": {
        "id": "i1Ev5T9ESlX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard over training"
      ],
      "metadata": {
        "id": "bQNTJbptTxgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "ocGm88ZjT4dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "dd8I3NAcUHYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "directory=str(lr)+\"_\"+str(g)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "4p7Lv7xzUIdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101"
      ],
      "metadata": {
        "id": "hN0G-x1GSljq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "q2xwmmnkUcJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) #load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ('robot_valid',)  #Give validation set to validate on\n",
        "cfg.TEST.EVAL_PERIOD = 200 #for every 200 iter the model will track validation loss \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\") #load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 #set to four so it can run in collab due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 2000 #number of iterations \n",
        "cfg.SOLVER.STEPS = (200)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr= 0.00025 # 0.03, 0.1 - replace variable with the desired lr option\n",
        "g= 0.1 # 0.01, 0.5 - replace variable with the desired gamma option\n",
        "cfg.SOLVER.BASE_LR =lr\n",
        "cfg.SOLVER.GAMMA =g\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #make output directory for output\n",
        "trainer= Trainer(cfg) #Use custom trainer with data augmentation\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() #Train model"
      ],
      "metadata": {
        "id": "5Kqr5s9lUdTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard over training"
      ],
      "metadata": {
        "id": "ENGqHAIaU9b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "t0GHw689U_vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save model"
      ],
      "metadata": {
        "id": "8GT4ZGecVCps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory=str(lr)+\"_\"+str(g)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "_WHqjC_wVDq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter search part 2: Lr, gamma and weight decay values"
      ],
      "metadata": {
        "id": "mnqL3ORiVpE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R50"
      ],
      "metadata": {
        "id": "TnxRfO6cVxd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "zpQ9JaohV2hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ('robot_valid',)  # Give validation set to track \n",
        "cfg.TEST.EVAL_PERIOD = 200 # for each 200 iter the model will track validationset\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 # Set to four to be able to run in collab due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 4000 # number of iterations\n",
        "cfg.SOLVER.STEPS = (500, 1000, 1500, 2000, 2500, 3000, 3500)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr = 0.05 # 0.1, 0.01, 0.05 - change lr to the option you want\n",
        "g= 0.01 # 0.01, 0.1 0.5 - change gamma to the option you want\n",
        "wd = 0.00025 #0.00025, 0.0005 - change weight decay to the option you want\n",
        "\n",
        "cfg.SOLVER.BASE_LR = lr\n",
        "cfg.SOLVER.GAMMA = g\n",
        "cfg.SOLVER.WEIGHT_DECAY = wd\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #create output directory for output\n",
        "trainer= Trainer(cfg) # use custom trainer with data augmentation\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() # train model"
      ],
      "metadata": {
        "id": "6thwohFkV43_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard over training"
      ],
      "metadata": {
        "id": "PJwe75gZV5rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "QOW6G-I7V45r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "UGy2VczPWATa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "directory=str(lr)+\"_\"+str(g)+\"_\"+str(wd)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "X-UJuG8VWB1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R101"
      ],
      "metadata": {
        "id": "zhX5MaXUVyuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "vuLPYLDeXYe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) #Load model\n",
        "cfg.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg.DATASETS.TEST = ('robot_valid',)  # Give validation set to track \n",
        "cfg.TEST.EVAL_PERIOD = 200 # for each 200 iter the model will track validationset\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\") #Load weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 # Set to four to be able to run in collab due to limited resources\n",
        "cfg.SOLVER.MAX_ITER = 4000 # number of iterations\n",
        "cfg.SOLVER.STEPS = (500, 1000, 1500, 2000, 2500, 3000, 3500)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "#Hyperparameters:\n",
        "lr = 0.05 # 0.1, 0.01, 0.05 - change lr to the option you want\n",
        "g= 0.01 # 0.01, 0.1 0.5 - change gamma to the option you want\n",
        "wd = 0.00025 #0.00025, 0.0005 - change weight decay to the option you want\n",
        "\n",
        "cfg.SOLVER.BASE_LR = lr\n",
        "cfg.SOLVER.GAMMA = g\n",
        "cfg.SOLVER.WEIGHT_DECAY = wd\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) #create output directory for output\n",
        "trainer= Trainer(cfg) # use custom trainer with data augmentation\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() # train model"
      ],
      "metadata": {
        "id": "v0ApXtpyXZlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard over training"
      ],
      "metadata": {
        "id": "4_uOAuiQVyxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "wTnmkJuuXnti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "1boglu0oXqQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory=str(lr)+\"_\"+str(g)+\"_\"+str(wd)\n",
        "drive='/content/drive/MyDrive'\n",
        "path=os.path.join(drive,directory)\n",
        "os.mkdir(path)\n",
        "src=\"/content/output/\"\n",
        "\n",
        "for f in os.scandir(src):\n",
        "  if f.is_dir():\n",
        "    newpath=os.path.join(path,f.name)\n",
        "    print(newpath)\n",
        "    os.mkdir(newpath)\n",
        "    for fi in os.scandir(f):\n",
        "      shutil.copy(fi,newpath)\n",
        "  elif f.is_file():\n",
        "    shutil.copy(f,path)"
      ],
      "metadata": {
        "id": "y2bA8zxKXreP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}