{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master's thesis - Backbone.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Detectron 2 and its dependencies "
      ],
      "metadata": {
        "id": "vQL4yY9uyDdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "\n"
      ],
      "metadata": {
        "id": "kPywhZ70yIak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "TQa8zStByQ1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\") \n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "#Import some common imports\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()"
      ],
      "metadata": {
        "id": "acBZB6jwyR9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "J2H6Ot8B0Lsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to drive"
      ],
      "metadata": {
        "id": "ACXtusyv0V2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') #This step should be avoided if data is not placed on drive"
      ],
      "metadata": {
        "id": "2HwUPkC_0Y2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the following code has taken inspiration from different resources: \n",
        "The function to convert data to coco format has taken inspiration from the \"Detectron 2 compare models + augmentation\" kaggle. URL:https://www.kaggle.com/code/dhiiyaur/detectron-2-compare-models-augmentation"
      ],
      "metadata": {
        "id": "zD3uLu2f4f6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make function to convert data to COCO format"
      ],
      "metadata": {
        "id": "__VBxgEO0gJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = filename\n",
        "        record[\"height\"] = 480\n",
        "        record[\"width\"] = 640\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly \n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "YlG3UkXG0t_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "RtE1lHRK018Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List the five classes \n",
        "classes = ['sink', 'door', 'bed', 'screen', 'socket']\n",
        "\n",
        "#Give path to data - if path is not on drive change the path before running\n",
        "data_path = '/content/drive/MyDrive/robotdata/Blue_ocean_dataset1/'\n",
        "\n",
        "for d in [\"train\", \"valid\", \"test\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"robot_\" + d, \n",
        "        lambda d=d: get_data_dicts(data_path+d, classes) #uses get_data_dicts function to make data into COCO format\n",
        "    )\n",
        "    MetadataCatalog.get(\"robot_\" + d).set(thing_classes=classes)\n",
        "\n",
        "#Collect the data into metadatacatalog \n",
        "microcontroller_metadata = MetadataCatalog.get(\"robot_train\")\n",
        "\n",
        "#Convert trainingset to COCO format and save as train_dicts\n",
        "train_dicts = get_data_dicts(data_path+'train', classes)\n",
        "\n",
        "#Convert validationset to COCO format and save as valid_dicts\n",
        "valid_dicts = get_data_dicts(data_path+'valid', classes)\n",
        "\n",
        "#Convert testset to COCO format and save as test_dicts\n",
        "test_dicts = get_data_dicts(data_path+'test', classes)\n"
      ],
      "metadata": {
        "id": "kz98ELu30UIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize loaded data"
      ],
      "metadata": {
        "id": "VCPQCVQZ17xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize for checking the data is loaded properly \n",
        "for d in random.sample(train_dicts, 5):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0voYxEko27h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing backbone "
      ],
      "metadata": {
        "id": "lWcFzSwz3cVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C4 backbone"
      ],
      "metadata": {
        "id": "_YURmtR-3s5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "hyqRY4Ki4-IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_C4 = get_cfg()\n",
        "cfg_C4.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\")) #Load the config file\n",
        "cfg_C4.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_C4.DATASETS.TEST = ('robot_valid',)   \n",
        "cfg_C4.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_C4.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\") #Load the weights\n",
        "cfg_C4.SOLVER.IMS_PER_BATCH = 4 #put to 4 or else it will not run on collab due to limited resources\n",
        "cfg_C4.SOLVER.MAX_ITER = 1000\n",
        "cfg_C4.SOLVER.STEPS = ()\n",
        "cfg_C4.MODEL.ROI_HEADS.NUM_CLASSES = 5 #number of classes\n",
        "\n",
        "os.makedirs(cfg_C4.OUTPUT_DIR, exist_ok=True)#make directory for output files from model\n",
        "trainer_C4 = DefaultTrainer(cfg_C4)  #Use default trainer\n",
        "trainer_C4.resume_or_load(resume=False)\n",
        "trainer_C4.train() #train model"
      ],
      "metadata": {
        "id": "nKmxr3pj4i0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "LQvfo1135g6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "cvo9qUyM5kRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluate model"
      ],
      "metadata": {
        "id": "yD09gIfq5m0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_C4.MODEL.WEIGHTS = os.path.join(cfg_C4.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_C4.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 #set threshold\n",
        "cfg_C4.DATASETS.TEST = (\"robot_test\",) # select testset \n",
        "predictor = DefaultPredictor(cfg_C4)"
      ],
      "metadata": {
        "id": "8cyXTSlY5prA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "Y3N7F3Yy6Hi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use COCO evaluator\n",
        "val_loader = build_detection_test_loader(cfg_C4, \"robot_test\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator)) #print evaluation matrix"
      ],
      "metadata": {
        "id": "T9HHrtLF6QBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "j5pLGqMs52lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for d in random.sample(test_dicts, 5): #gives 5 random samples from the testset\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "-z_ZmdCV55lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "WV5H6Nl16r1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_C4, 'model_final.pth')"
      ],
      "metadata": {
        "id": "Oxc4dmGr6tsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DC5"
      ],
      "metadata": {
        "id": "bY_6dKE54PJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "4BLkFyJL6xCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_dc5 = get_cfg()\n",
        "cfg_dc5.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml\")) #Load model \n",
        "cfg_dc5.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_dc5.DATASETS.TEST = ('robot_valid',)  \n",
        "cfg_dc5.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_dc5.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml\") #Load weights from model\n",
        "cfg_dc5.SOLVER.IMS_PER_BATCH = 4 #set to 4 or collab will not run due to limited resources\n",
        "cfg_dc5.SOLVER.MAX_ITER = 1000\n",
        "cfg_dc5.SOLVER.STEPS = ()\n",
        "cfg_dc5.MODEL.ROI_HEADS.NUM_CLASSES = 5 #Number of classes\n",
        "\n",
        "os.makedirs(cfg_dc5.OUTPUT_DIR, exist_ok=True) #Create directory for output\n",
        "trainer_dc5 = DefaultTrainer(cfg_dc5)  #Use default trainer\n",
        "trainer_dc5.resume_or_load(resume=False)\n",
        "trainer_dc5.train() #Train model "
      ],
      "metadata": {
        "id": "ixM4nO7b61Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "SawAc8jP61Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "6yfvlK5D64YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "lnPNT62c64i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_dc5.MODEL.WEIGHTS = os.path.join(cfg_dc5.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_dc5.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 # Set threshold\n",
        "cfg_dc5.DATASETS.TEST = (\"robot_test\",) # Give testset\n",
        "predictor_dc5 = DefaultPredictor(cfg_dc5) #Make predictions"
      ],
      "metadata": {
        "id": "LAbQ2dQi67U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "VnlSTaAt67fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_dc5 = COCOEvaluator(\"robot_test\", output_dir=\"./output\") #Use coco evaluator\n",
        "val_loader_dc5 = build_detection_test_loader(cfg_dc5, \"robot_test\")\n",
        "print(inference_on_dataset(predictor_dc5.model, val_loader_dc5, evaluator_dc5)) #Print evaluation matrix"
      ],
      "metadata": {
        "id": "A6-6pI6669nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "0ujumVS669wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows five random predictions from the test set\n",
        "for d in random.sample(test_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_dc5(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "qUjdDQJj7Bm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "_2lb2MDC7B7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_dc5, 'model_dc5_final.pth')"
      ],
      "metadata": {
        "id": "m0eZ9SAM4Sx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPN backbone"
      ],
      "metadata": {
        "id": "T1Q7oSgC4TDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on baseline model"
      ],
      "metadata": {
        "id": "t_hkueIz8FAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn = get_cfg()\n",
        "cfg_fpn.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")) # Load model\n",
        "cfg_fpn.DATASETS.TRAIN = ('robot_train',)\n",
        "cfg_fpn.DATASETS.TEST = ('robot_valid',)  \n",
        "cfg_fpn.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_fpn.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\") #Load weights\n",
        "cfg_fpn.SOLVER.IMS_PER_BATCH = 4 #Set to four else it cannot run on collab due to resource limitations\n",
        "cfg_fpn.SOLVER.MAX_ITER = 1000\n",
        "cfg_fpn.SOLVER.STEPS = ()\n",
        "cfg_fpn.MODEL.ROI_HEADS.NUM_CLASSES = 5 # Number of classes \n",
        "\n",
        "os.makedirs(cfg_fpn.OUTPUT_DIR, exist_ok=True) #Make directory for output of model\n",
        "trainer_fpn = DefaultTrainer(cfg_fpn) # Use default trainer\n",
        "trainer_fpn.resume_or_load(resume=False)\n",
        "trainer_fpn.train() #Train model"
      ],
      "metadata": {
        "id": "am7Lf-NV8IWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard over training"
      ],
      "metadata": {
        "id": "lf7lr56n8IhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "ZK0_Vc0D8KiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and evaluation"
      ],
      "metadata": {
        "id": "EHj77tTV8Kq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_fpn.MODEL.WEIGHTS = os.path.join(cfg_fpn.OUTPUT_DIR, \"model_fpn_final.pth\")\n",
        "cfg_fpn.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 #Set threshold \n",
        "cfg_fpn.DATASETS.TEST = (\"robot_test\",) #Fed testset\n",
        "predictor_fpn = DefaultPredictor(cfg_fpn) #Predict on testset"
      ],
      "metadata": {
        "id": "Nq7-BXzI8NRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation matrix"
      ],
      "metadata": {
        "id": "S_AnAlnB8PAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_fpn = COCOEvaluator(\"robot_test\", output_dir=\"./output\") # Use COCO evaluator\n",
        "val_loader_fpn = build_detection_test_loader(cfg_fpn, \"robot_test\")\n",
        "print(inference_on_dataset(predictor_fpn.model, val_loader_fpn, evaluator_fpn)) #Print evaluation"
      ],
      "metadata": {
        "id": "LSELCN4H8NUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of predictions"
      ],
      "metadata": {
        "id": "fiT5qRnz8W7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for d in random.sample(test_dicts, 5):       \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_fpn(im) \n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(out.get_image()[:, :, ::-1][..., ::-1])"
      ],
      "metadata": {
        "id": "7Dsj4ev74iTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "sI7e-MFa8g89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cfg_dc5, 'model_dc5_final.pth')"
      ],
      "metadata": {
        "id": "rpkCq8CH8c2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}